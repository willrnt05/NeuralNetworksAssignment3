{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2367d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Device Available\n",
      "Name of the Cuda Device:  NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "GPU Computational Capablity:  (8, 6)\n",
      "Epoch: 0 Loss: 23.01865577697754\n",
      "Epoch: 10 Loss: 0.5777960419654846\n",
      "Epoch: 20 Loss: 1.1167500019073486\n",
      "Epoch: 30 Loss: 1.0041793584823608\n",
      "Epoch: 40 Loss: 0.21788427233695984\n",
      "Epoch: 50 Loss: 0.27820006012916565\n",
      "Epoch: 60 Loss: 0.030120650306344032\n",
      "Epoch: 70 Loss: 0.08673684298992157\n",
      "Epoch: 80 Loss: 0.04102488234639168\n",
      "Epoch: 90 Loss: 0.0301812831312418\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Cuda Device Available\")\n",
    "    print(\"Name of the Cuda Device: \", torch.cuda.get_device_name())\n",
    "    print(\"GPU Computational Capablity: \", torch.cuda.get_device_capability())\n",
    "\n",
    "\"\"\"\n",
    "def ChangeDateShiller(date):\n",
    "    date = date.split()\n",
    "    firstElement = date[0]\n",
    "    firstElement = firstElement.split('-')\n",
    "    firstElement[0], firstElement[1] = firstElement[1], firstElement[0]\n",
    "    firstElement[1], firstElement[2] = firstElement[2], firstElement[1]\n",
    "    if len(firstElement[0]) == 1:\n",
    "        firstElement[0] = \"0\" + firstElement\n",
    "    if len(firstElement[1]) == 1:\n",
    "        firstElement[1] = \"0\" + firstElement\n",
    "    firstElement = \"/\".join(firstElement)\n",
    "    return firstElement\n",
    "\"\"\"\n",
    "\n",
    "#Rough Estimate made Graphically\n",
    "def MultiplyPE(pe):\n",
    "    pe = pe * 25\n",
    "    return pe\n",
    "\n",
    "#Scales PE for 2012 y intercept\n",
    "def ScalePERatio(df):\n",
    "    df['Shiller PE Ratio'] = df['Shiller PE Ratio'].apply(MultiplyPE)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def BuildSandPDataSet():\n",
    "    df = pd.read_csv(\"SandP500Data.csv\", sep = ',')\n",
    "    #df.drop('Volume', inplace = True, axis=1)\n",
    "    df = df.sort_index(axis=0,ascending=False).reset_index()\n",
    "    df.drop('index', inplace = True, axis = 1)\n",
    "    return df\n",
    "\n",
    "def BuildShillerPeDataSet():\n",
    "    df = pd.read_csv(\"ShillerPERatio.csv\", sep = ',', skiprows = [0])\n",
    "    df = df.rename(columns={'DateTime': 'Date'})\n",
    "    #df['Date'] = df['Date'].apply(ChangeDateShiller)\n",
    "    df = df.sort_index(axis=0,ascending=False).reset_index()\n",
    "    df.drop('index', inplace = True, axis = 1)\n",
    "    return df\n",
    "\n",
    "def BuildDataset():\n",
    "    SP = BuildSandPDataSet()\n",
    "    PE = BuildShillerPeDataSet()\n",
    "    df = pd.merge(SP, PE, how=\"inner\", on=[\"Date\"])\n",
    "    df = df[['Date', 'Open', 'High', 'Low', 'Volume', 'Shiller PE Ratio', 'Close']]\n",
    "    return df\n",
    "\n",
    "def MergeByDate(df1, df2):\n",
    "    dfinal = df1.merge(df2, on=\"Date\", how = 'inner')\n",
    "    return dfinal\n",
    "\n",
    "\n",
    "#Looks like the derivatives of each are correlated\n",
    "#Even though maybe the magnitudes are not\n",
    "def GraphPEToClose(SandPData, PEData, logy = True):\n",
    "    if logy == False:\n",
    "        #PEData = ScalePERatio(PEData)\n",
    "        title = \"Graph of S&P and Schiller PE\"\n",
    "    else:\n",
    "         title = \"Graph of S&P and Schiller PE\"\n",
    "       \n",
    "    dfinal = MergeByDate(SandPData, PEData)\n",
    "    dfinal[:].plot(x='Date', y=['Close', 'Shiller PE Ratio'], figsize=(10,5), logy = logy, title = title, grid=True)\n",
    "\n",
    "def PEGraph():\n",
    "    SP = BuildSandPDataSet()\n",
    "    PE = BuildShillerPeDataSet()\n",
    "    GraphPEToClose(SP, PE)\n",
    "    \n",
    "def BuildInputSequence(dataset, window, prediction):\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0, len(dataset) - window + 1 - prediction):\n",
    "        feature = []\n",
    "        label = []\n",
    "        for j in range(0, window):\n",
    "            row = []\n",
    "            row.append(np.log(dataset['Open'][i + j]))\n",
    "            row.append(np.log(dataset['High'][i + j]))\n",
    "            row.append(np.log(dataset['Low'][i + j]))\n",
    "            row.append(np.log(dataset['Volume'][i + j]))\n",
    "            row.append(np.log(dataset['Shiller PE Ratio'][i + j]))\n",
    "            row.append(np.log(dataset['Close'][i + j]))\n",
    "            feature.append(row)\n",
    "\n",
    "        for j in range(0, prediction):\n",
    "            label.append(np.log(dataset['Open'][i + j]))\n",
    "            label.append(np.log(dataset['High'][i + j]))\n",
    "            label.append(np.log(dataset['Low'][i + j]))\n",
    "            label.append(np.log(dataset['Volume'][i + j]))\n",
    "            label.append(np.log(dataset['Shiller PE Ratio'][i + j]))\n",
    "            label.append(np.log(dataset['Close'])[i + window + j])\n",
    "\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return [features, labels]\n",
    "\n",
    "def TrainTestDataset(window = 1, prediction = 1):\n",
    "    df = BuildDataset()\n",
    "    a = BuildInputSequence(df, window, prediction)\n",
    "   \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(a[0], a[1], test_size = 0.2)\n",
    "\n",
    "    #X_train = a[0][:round(len(a[0])/2)]\n",
    "    #Y_train = a[0][(len(a[0]) - round(len(a[0])/2)) + 1:]\n",
    "\n",
    "    #X_test = a[1][:round(len(a[1])/2)]\n",
    "    #Y_test = a[1][(len(a[1]) - round(len(a[1])/2)) + 1:]\n",
    "    \n",
    "    return [X_train, Y_train, X_test, Y_test]\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_size, layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.layers, batch_size, self.hidden_size).to(device)\n",
    "        return hidden\n",
    "    \n",
    "def Train(Model, X_train, Y_train, epochs, batchSize, learningRate):\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(Model.parameters(), lr=learningRate)\n",
    "    \n",
    "    dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "    dataLoader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batchSize, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, label) in enumerate(dataLoader):\n",
    "            data = data.to(device)\n",
    "            label = label.type(torch.float32)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output, hidden = Model(data)\n",
    "            #output = output.squeeze(1)\n",
    "            output = output.float()\n",
    "            label = label.float()\n",
    "            #print(str(data), \"\\n\")\n",
    "            #print(str(output), \"\\n\")\n",
    "            #print(str(label), \"\\n\")\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #if(loss.item() < 0.01):\n",
    "                #print(\"Done Training..\")\n",
    "                #return\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch: \" + str(epoch) + \" Loss: \" + str(loss.item()))\n",
    "    \n",
    "#rnn = RNN(6, 32, 1)\n",
    "D = TrainTestDataset(1)\n",
    "X_train, Y_train, X_test, Y_test = D[0], D[1], D[2], D[3]\n",
    "\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "Y_train = torch.Tensor(Y_train)\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "\n",
    "Model = RNN(6, 6, 32, 1)\n",
    "Model = Model.to(device)\n",
    "\n",
    "Train(Model, X_train, Y_train, 100, 10, 0.01)\n",
    "\n",
    "\n",
    "\n",
    "#Getting Input size[30]\n",
    "#Expecting Output size [10, 1]\n",
    "\n",
    "#Getting Input size[12]\n",
    "#Expecting Output size [4, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3329b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.3893,  5.4333,  5.3507, 21.6214,  2.7348,  5.4069],\n",
      "        [ 7.2684,  7.3087,  7.2259, 24.5656,  3.2537,  7.2737],\n",
      "        [ 7.6718,  7.7112,  7.6285, 25.1974,  3.3651,  7.6745],\n",
      "        [ 6.5035,  6.5454,  6.4627, 23.3676,  3.0427,  6.5138],\n",
      "        [ 7.6294,  7.6689,  7.5861, 25.1309,  3.3533,  7.6324],\n",
      "        [ 7.6327,  7.6721,  7.5894, 25.1360,  3.3543,  7.6356],\n",
      "        [ 5.7276,  5.7712,  5.6885, 22.1521,  2.8285,  5.7430],\n",
      "        [ 7.7365,  7.7757,  7.6930, 25.2986,  3.3829,  7.7387],\n",
      "        [ 6.1994,  6.2419,  6.1593, 22.8911,  2.9587,  6.2117],\n",
      "        [ 7.7326,  7.7718,  7.6890, 25.2924,  3.3818,  7.7348]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "171.2489561244735"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def PredictAhead(M, XInit, FarAhead):\n",
    "    output = XInit\n",
    "    for _ in range(FarAhead):\n",
    "        output, hidden = M(output)\n",
    "        output = torch.Tensor([output.cpu().detach().numpy()]).to(device)\n",
    "        #print(output)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    return math.e**output[-1][-1][-1]\n",
    "\n",
    "#print(Model(X_train[0:1].to(device))[0])\n",
    "print(Model(X_train[0:10].to(device))[0])\n",
    "#print(type(X_train[0:1].to(device)))\n",
    "PredictAhead(Model, X_train[0:10].to(device), 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049695d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
