{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d2367d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 26.050697326660156\n",
      "Epoch: 10 Loss: 0.9161461591720581\n",
      "Epoch: 20 Loss: 0.2668100595474243\n",
      "Epoch: 30 Loss: 0.07120290398597717\n",
      "Epoch: 40 Loss: 0.1366715133190155\n",
      "Epoch: 50 Loss: 0.11425287276506424\n",
      "Epoch: 60 Loss: 0.04849095270037651\n",
      "Epoch: 70 Loss: 0.04103562608361244\n",
      "Epoch: 80 Loss: 0.026546698063611984\n",
      "Epoch: 90 Loss: 0.009111122228205204\n",
      "Epoch: 100 Loss: 0.053307682275772095\n",
      "Epoch: 110 Loss: 0.024628030136227608\n",
      "Epoch: 120 Loss: 0.024579429998993874\n",
      "Epoch: 130 Loss: 0.03734736144542694\n",
      "Epoch: 140 Loss: 0.026211053133010864\n",
      "Epoch: 150 Loss: 0.023989230394363403\n",
      "Epoch: 160 Loss: 0.031053433194756508\n",
      "Epoch: 170 Loss: 0.026591042056679726\n",
      "Epoch: 180 Loss: 0.024981698021292686\n",
      "Epoch: 190 Loss: 0.020448049530386925\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Cuda Device Available\")\n",
    "    print(\"Name of the Cuda Device: \", torch.cuda.get_device_name())\n",
    "    print(\"GPU Computational Capablity: \", torch.cuda.get_device_capability())\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\"\"\"\n",
    "def ChangeDateShiller(date):\n",
    "    date = date.split()\n",
    "    firstElement = date[0]\n",
    "    firstElement = firstElement.split('-')\n",
    "    firstElement[0], firstElement[1] = firstElement[1], firstElement[0]\n",
    "    firstElement[1], firstElement[2] = firstElement[2], firstElement[1]\n",
    "    if len(firstElement[0]) == 1:\n",
    "        firstElement[0] = \"0\" + firstElement\n",
    "    if len(firstElement[1]) == 1:\n",
    "        firstElement[1] = \"0\" + firstElement\n",
    "    firstElement = \"/\".join(firstElement)\n",
    "    return firstElement\n",
    "\"\"\"\n",
    "\n",
    "#Rough Estimate made Graphically\n",
    "def MultiplyPE(pe):\n",
    "    pe = pe * 25\n",
    "    return pe\n",
    "\n",
    "#Scales PE for 2012 y intercept\n",
    "def ScalePERatio(df):\n",
    "    df['Shiller PE Ratio'] = df['Shiller PE Ratio'].apply(MultiplyPE)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def BuildSandPDataSet():\n",
    "    df = pd.read_csv(\"SandP500Data.csv\", sep = ',')\n",
    "    #df.drop('Volume', inplace = True, axis=1)\n",
    "    df = df.sort_index(axis=0,ascending=False).reset_index()\n",
    "    df.drop('index', inplace = True, axis = 1)\n",
    "    return df\n",
    "\n",
    "def BuildShillerPeDataSet():\n",
    "    df = pd.read_csv(\"ShillerPERatio.csv\", sep = ',', skiprows = [0])\n",
    "    df = df.rename(columns={'DateTime': 'Date'})\n",
    "    #df['Date'] = df['Date'].apply(ChangeDateShiller)\n",
    "    df = df.sort_index(axis=0,ascending=False).reset_index()\n",
    "    df.drop('index', inplace = True, axis = 1)\n",
    "    return df\n",
    "\n",
    "def BuildDataset():\n",
    "    SP = BuildSandPDataSet()\n",
    "    PE = BuildShillerPeDataSet()\n",
    "    df = pd.merge(SP, PE, how=\"inner\", on=[\"Date\"])\n",
    "    df = df[['Date', 'Open', 'High', 'Low', 'Volume', 'Shiller PE Ratio', 'Close']]\n",
    "    return df\n",
    "\n",
    "def MergeByDate(df1, df2):\n",
    "    dfinal = df1.merge(df2, on=\"Date\", how = 'inner')\n",
    "    return dfinal\n",
    "\n",
    "\n",
    "#Looks like the derivatives of each are correlated\n",
    "#Even though maybe the magnitudes are not\n",
    "def GraphPEToClose(SandPData, PEData, logy = True):\n",
    "    if logy == False:\n",
    "        #PEData = ScalePERatio(PEData)\n",
    "        title = \"Graph of S&P and Schiller PE\"\n",
    "    else:\n",
    "         title = \"Graph of S&P and Schiller PE\"\n",
    "       \n",
    "    dfinal = MergeByDate(SandPData, PEData)\n",
    "    dfinal[:].plot(x='Date', y=['Close', 'Shiller PE Ratio'], figsize=(10,5), logy = logy, title = title, grid=True)\n",
    "\n",
    "def PEGraph():\n",
    "    SP = BuildSandPDataSet()\n",
    "    PE = BuildShillerPeDataSet()\n",
    "    GraphPEToClose(SP, PE)\n",
    "    \n",
    "def BuildInputSequence(dataset, window, prediction):\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0, len(dataset) - window + 1 - prediction):\n",
    "        feature = []\n",
    "        label = []\n",
    "        for j in range(0, window):\n",
    "            row = []\n",
    "            row.append(np.log(dataset['Open'][i + j]))\n",
    "            row.append(np.log(dataset['High'][i + j]))\n",
    "            row.append(np.log(dataset['Low'][i + j]))\n",
    "            row.append(np.log(dataset['Volume'][i + j]))\n",
    "            row.append(np.log(dataset['Shiller PE Ratio'][i + j]))\n",
    "            row.append(np.log(dataset['Close'][i + j]))\n",
    "            feature.append(row)\n",
    "\n",
    "        for j in range(0, prediction):\n",
    "            label.append(np.log(dataset['Open'][i + window + j]))\n",
    "            label.append(np.log(dataset['High'][i + window + j]))\n",
    "            label.append(np.log(dataset['Low'][i + window + j]))\n",
    "            label.append(np.log(dataset['Volume'][i + window + j]))\n",
    "            label.append(np.log(dataset['Shiller PE Ratio'][i + window + j]))\n",
    "            label.append(np.log(dataset['Close'])[i + window + j])\n",
    "\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return [features, labels]\n",
    "\n",
    "def TrainTestDataset(window = 1, prediction = 1):\n",
    "    df = BuildDataset()\n",
    "    a = BuildInputSequence(df, window, prediction)\n",
    "   \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(a[0], a[1], test_size = 0.2)\n",
    "\n",
    "    #X_train = a[0][:round(len(a[0])/2)]\n",
    "    #Y_train = a[0][(len(a[0]) - round(len(a[0])/2)) + 1:]\n",
    "\n",
    "    #X_test = a[1][:round(len(a[1])/2)]\n",
    "    #Y_test = a[1][(len(a[1]) - round(len(a[1])/2)) + 1:]\n",
    "    \n",
    "    return [X_train, Y_train, X_test, Y_test]\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_size, layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.layers, batch_size, self.hidden_size).to(device)\n",
    "        return hidden\n",
    "    \n",
    "def Train(Model, X_train, Y_train, epochs, batchSize, learningRate):\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(Model.parameters(), lr=learningRate)\n",
    "    \n",
    "    dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "    dataLoader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batchSize, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, label) in enumerate(dataLoader):\n",
    "            data = data.to(device)\n",
    "            label = label.type(torch.float32)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output, hidden = Model(data)\n",
    "            #output = output.squeeze(1)\n",
    "            output = output.float()\n",
    "            label = label.float()\n",
    "            #print(str(data), \"\\n\")\n",
    "            #print(str(output), \"\\n\")\n",
    "            #print(str(label), \"\\n\")\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #if(loss.item() < 0.01):\n",
    "                #print(\"Done Training..\")\n",
    "                #return\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch: \" + str(epoch) + \" Loss: \" + str(loss.item()))\n",
    "    \n",
    "#rnn = RNN(6, 32, 1)\n",
    "D = TrainTestDataset(1)\n",
    "X_train, Y_train, X_test, Y_test = D[0], D[1], D[2], D[3]\n",
    "\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "Y_train = torch.Tensor(Y_train)\n",
    "\n",
    "X_test = torch.Tensor(X_test)\n",
    "Y_test = torch.Tensor(Y_test)\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "\n",
    "Model = RNN(6, 6, 32, 1)\n",
    "Model = Model.to(device)\n",
    "\n",
    "Train(Model, X_train, Y_train, 200, 10, 0.01)\n",
    "\n",
    "\n",
    "\n",
    "#Getting Input size[30]\n",
    "#Expecting Output size [10, 1]\n",
    "\n",
    "#Getting Input size[12]\n",
    "#Expecting Output size [4, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3329b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 7.9998,  8.0109,  7.9452, 25.1003,  3.3572,  7.9815]],\n",
      "\n",
      "        [[ 6.2793,  6.3119,  6.2653, 22.7456,  3.1232,  6.3003]],\n",
      "\n",
      "        [[ 6.0770,  6.0928,  6.0565, 22.3874,  3.0116,  6.0840]],\n",
      "\n",
      "        [[ 6.5082,  6.5160,  6.4067, 22.9037,  3.2133,  6.4614]],\n",
      "\n",
      "        [[ 5.5331,  5.5378,  5.4297, 21.8758,  2.6005,  5.4438]],\n",
      "\n",
      "        [[ 6.7035,  6.8106,  6.6446, 24.3571,  3.0892,  6.7864]],\n",
      "\n",
      "        [[ 7.5819,  7.5966,  7.5656, 24.9208,  3.2511,  7.5656]],\n",
      "\n",
      "        [[ 7.0452,  7.0456,  6.9693, 24.0756,  3.3676,  6.9819]],\n",
      "\n",
      "        [[ 6.2160,  6.2447,  6.2150, 22.5649,  3.0745,  6.2436]],\n",
      "\n",
      "        [[ 7.3974,  7.4111,  7.3527, 25.0400,  3.1324,  7.3817]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2799.842165311102"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def PredictAhead(M, XInit, FarAhead):\n",
    "    output = XInit\n",
    "    for _ in range(FarAhead):\n",
    "        output, hidden = M(output)\n",
    "        output = torch.Tensor([output.cpu().detach().numpy()]).to(device)\n",
    "        #print(output)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    return math.e**output[-1][-1][-1]\n",
    "\n",
    "#print(Model(X_train[0:1].to(device))[0])\n",
    "print(X_train[0:10])\n",
    "#print(Model(X_train[0:10].to(device))[0])\n",
    "#print(type(X_train[0:1].to(device)))\n",
    "PredictAhead(Model, X_train[0:5].to(device), 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d049695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(M):\n",
    "    \n",
    "    data = BuildDataset().to_dict('split')['data']\n",
    "    \n",
    "    dates = []\n",
    "    for i in range(len(data)):\n",
    "        dates.append(data[i][0])\n",
    "        \n",
    "    \n",
    "    #for one day prediction on train data\n",
    "    trainOne = []\n",
    "    \n",
    "    for i in range(len(X_train) - 7):\n",
    "        trainOne.append(PredictAhead(Model, X_train[i:i + 5].to(device), 1))\n",
    "        \n",
    "    #for one day prediction on test data\n",
    "    testOne = []\n",
    "    \n",
    "    for i in range(len(X_test) - 7):\n",
    "        testOne.append(PredictAhead(Model, X_test[i:i + 5].to(device), 1))\n",
    "    \n",
    "    #for two day prediction on train data\n",
    "    trainTwo = []\n",
    "    \n",
    "    for i in range(len(X_train) - 8):\n",
    "        trainTwo.append(PredictAhead(Model, X_train[i:i + 5].to(device), 2))\n",
    "    \n",
    "    #for two day prediction on test data\n",
    "    testTwo = []\n",
    "    \n",
    "    for i in range(len(X_test) - 8):\n",
    "        testTwo.append(PredictAhead(Model, X_test[i:i + 5].to(device), 2))\n",
    "    \n",
    "    #for three day prediction on train data\n",
    "    trainThree = []\n",
    "    \n",
    "    for i in range(len(X_train) - 9):\n",
    "        trainThree.append(PredictAhead(Model, X_train[i:i + 5].to(device), 3))\n",
    "    \n",
    "    #for three day prediction on test data\n",
    "    testThree = []\n",
    "    \n",
    "    for i in range(len(X_test) - 9):\n",
    "        testThree.append(PredictAhead(Model, X_test[i:i + 5].to(device), 3))\n",
    "    \n",
    "    #for four day prediction on train data\n",
    "    trainFour = []\n",
    "    \n",
    "    for i in range(len(X_train) - 10):\n",
    "        trainFour.append(PredictAhead(Model, X_train[i:i + 5].to(device), 4))\n",
    "    \n",
    "    #for four day prediction on test data\n",
    "    testFour = []\n",
    "    \n",
    "    for i in range(len(X_test) - 10):\n",
    "        testFour.append(PredictAhead(Model, X_test[i:i + 5].to(device), 4))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cd06151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c958d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
