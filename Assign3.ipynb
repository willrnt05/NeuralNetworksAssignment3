{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2367d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Device Available\n",
      "Name of the Cuda Device:  NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "GPU Computational Capablity:  (8, 6)\n",
      "Epoch: 0 Loss: 0.892368495464325\n",
      "Epoch: 1 Loss: 0.626775860786438\n",
      "Epoch: 2 Loss: 0.4531162679195404\n",
      "Epoch: 3 Loss: 0.5295746326446533\n",
      "Epoch: 4 Loss: 0.9807287454605103\n",
      "Epoch: 5 Loss: 0.4141603708267212\n",
      "Epoch: 6 Loss: 1.0806300640106201\n",
      "Epoch: 7 Loss: 0.5280286073684692\n",
      "Epoch: 8 Loss: 0.8709087371826172\n",
      "Epoch: 9 Loss: 0.9116748571395874\n",
      "Epoch: 10 Loss: 0.861945629119873\n",
      "Epoch: 11 Loss: 0.09044738113880157\n",
      "Epoch: 12 Loss: 0.5059970617294312\n",
      "Epoch: 13 Loss: 0.473993718624115\n",
      "Epoch: 14 Loss: 0.4133793115615845\n",
      "Epoch: 15 Loss: 0.6593553423881531\n",
      "Epoch: 16 Loss: 1.1558674573898315\n",
      "Epoch: 17 Loss: 0.976487398147583\n",
      "Epoch: 18 Loss: 0.645256757736206\n",
      "Epoch: 19 Loss: 0.03499095141887665\n",
      "Epoch: 20 Loss: 1.203829288482666\n",
      "Epoch: 21 Loss: 0.8012686967849731\n",
      "Epoch: 22 Loss: 0.7101081609725952\n",
      "Epoch: 23 Loss: 0.4729779362678528\n",
      "Epoch: 24 Loss: 0.8352971076965332\n",
      "Epoch: 25 Loss: 0.3698462247848511\n",
      "Epoch: 26 Loss: 0.5507938861846924\n",
      "Epoch: 27 Loss: 0.7808459997177124\n",
      "Epoch: 28 Loss: 0.34205684065818787\n",
      "Epoch: 29 Loss: 0.5558173060417175\n",
      "Epoch: 30 Loss: 0.9586901664733887\n",
      "Epoch: 31 Loss: 0.3915879428386688\n",
      "Epoch: 32 Loss: 0.34629201889038086\n",
      "Epoch: 33 Loss: 0.1517147421836853\n",
      "Epoch: 34 Loss: 0.1668049544095993\n",
      "Epoch: 35 Loss: 0.01904348097741604\n",
      "Epoch: 36 Loss: 0.045046135783195496\n",
      "Epoch: 37 Loss: 0.017866363748908043\n",
      "Epoch: 38 Loss: 0.014017402194440365\n",
      "Epoch: 39 Loss: 0.010122360661625862\n",
      "Epoch: 40 Loss: 0.012536304071545601\n",
      "Epoch: 41 Loss: 0.036589886993169785\n",
      "Epoch: 42 Loss: 0.0478750579059124\n",
      "Epoch: 43 Loss: 0.02530095726251602\n",
      "Epoch: 44 Loss: 0.013622181490063667\n",
      "Epoch: 45 Loss: 0.028922993689775467\n",
      "Epoch: 46 Loss: 0.01231846772134304\n",
      "Epoch: 47 Loss: 0.011886155232787132\n",
      "Epoch: 48 Loss: 0.026561444625258446\n",
      "Epoch: 49 Loss: 0.011521640233695507\n",
      "Epoch: 50 Loss: 0.008399846963584423\n",
      "Epoch: 51 Loss: 0.00872797705233097\n",
      "Epoch: 52 Loss: 0.040343061089515686\n",
      "Epoch: 53 Loss: 0.012193908914923668\n",
      "Epoch: 54 Loss: 0.012123729102313519\n",
      "Epoch: 55 Loss: 0.006291481666266918\n",
      "Epoch: 56 Loss: 0.004724360536783934\n",
      "Epoch: 57 Loss: 0.019236356019973755\n",
      "Epoch: 58 Loss: 0.010031500831246376\n",
      "Epoch: 59 Loss: 0.002171684056520462\n",
      "Epoch: 60 Loss: 0.007861717604100704\n",
      "Epoch: 61 Loss: 0.005137817934155464\n",
      "Epoch: 62 Loss: 0.011762954294681549\n",
      "Epoch: 63 Loss: 0.008701568469405174\n",
      "Epoch: 64 Loss: 0.0057590617798268795\n",
      "Epoch: 65 Loss: 0.0050192843191325665\n",
      "Epoch: 66 Loss: 0.007831672206521034\n",
      "Epoch: 67 Loss: 0.013229943811893463\n",
      "Epoch: 68 Loss: 0.008886288851499557\n",
      "Epoch: 69 Loss: 0.013650452718138695\n",
      "Epoch: 70 Loss: 0.006100284866988659\n",
      "Epoch: 71 Loss: 0.013919073157012463\n",
      "Epoch: 72 Loss: 0.005021435208618641\n",
      "Epoch: 73 Loss: 0.0037096156738698483\n",
      "Epoch: 74 Loss: 0.02255197986960411\n",
      "Epoch: 75 Loss: 0.004378841258585453\n",
      "Epoch: 76 Loss: 0.004667081870138645\n",
      "Epoch: 77 Loss: 0.00397864542901516\n",
      "Epoch: 78 Loss: 0.005928426049649715\n",
      "Epoch: 79 Loss: 0.012688900344073772\n",
      "Epoch: 80 Loss: 0.00352002726867795\n",
      "Epoch: 81 Loss: 0.016297414898872375\n",
      "Epoch: 82 Loss: 0.0025129045825451612\n",
      "Epoch: 83 Loss: 0.0014954586513340473\n",
      "Epoch: 84 Loss: 0.007882035337388515\n",
      "Epoch: 85 Loss: 0.013402266427874565\n",
      "Epoch: 86 Loss: 0.005614974536001682\n",
      "Epoch: 87 Loss: 0.007424652576446533\n",
      "Epoch: 88 Loss: 0.028142821043729782\n",
      "Epoch: 89 Loss: 0.014957441948354244\n",
      "Epoch: 90 Loss: 0.011191045865416527\n",
      "Epoch: 91 Loss: 0.008758037351071835\n",
      "Epoch: 92 Loss: 0.0032791621051728725\n",
      "Epoch: 93 Loss: 0.006305324845016003\n",
      "Epoch: 94 Loss: 0.004948994144797325\n",
      "Epoch: 95 Loss: 0.01811564527451992\n",
      "Epoch: 96 Loss: 0.01757785677909851\n",
      "Epoch: 97 Loss: 0.03631757199764252\n",
      "Epoch: 98 Loss: 0.0013796265702694654\n",
      "Epoch: 99 Loss: 0.01422862522304058\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Cuda Device Available\")\n",
    "    print(\"Name of the Cuda Device: \", torch.cuda.get_device_name())\n",
    "    print(\"GPU Computational Capablity: \", torch.cuda.get_device_capability())\n",
    "\n",
    "\"\"\"\n",
    "def ChangeDateShiller(date):\n",
    "    date = date.split()\n",
    "    firstElement = date[0]\n",
    "    firstElement = firstElement.split('-')\n",
    "    firstElement[0], firstElement[1] = firstElement[1], firstElement[0]\n",
    "    firstElement[1], firstElement[2] = firstElement[2], firstElement[1]\n",
    "    if len(firstElement[0]) == 1:\n",
    "        firstElement[0] = \"0\" + firstElement\n",
    "    if len(firstElement[1]) == 1:\n",
    "        firstElement[1] = \"0\" + firstElement\n",
    "    firstElement = \"/\".join(firstElement)\n",
    "    return firstElement\n",
    "\"\"\"\n",
    "\n",
    "#Rough Estimate made Graphically\n",
    "def MultiplyPE(pe):\n",
    "    pe = pe * 25\n",
    "    return pe\n",
    "\n",
    "#Scales PE for 2012 y intercept\n",
    "def ScalePERatio(df):\n",
    "    df['Shiller PE Ratio'] = df['Shiller PE Ratio'].apply(MultiplyPE)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def BuildSandPDataSet():\n",
    "    df = pd.read_csv(\"SandP500Data.csv\", sep = ',')\n",
    "    #df.drop('Volume', inplace = True, axis=1)\n",
    "    df = df.sort_index(axis=0,ascending=False).reset_index()\n",
    "    df.drop('index', inplace = True, axis = 1)\n",
    "    return df\n",
    "\n",
    "def BuildShillerPeDataSet():\n",
    "    df = pd.read_csv(\"ShillerPERatio.csv\", sep = ',', skiprows = [0])\n",
    "    df = df.rename(columns={'DateTime': 'Date'})\n",
    "    #df['Date'] = df['Date'].apply(ChangeDateShiller)\n",
    "    df = df.sort_index(axis=0,ascending=False).reset_index()\n",
    "    df.drop('index', inplace = True, axis = 1)\n",
    "    return df\n",
    "\n",
    "def BuildDataset():\n",
    "    SP = BuildSandPDataSet()\n",
    "    PE = BuildShillerPeDataSet()\n",
    "    df = pd.merge(SP, PE, how=\"inner\", on=[\"Date\"])\n",
    "    df = df[['Date', 'Open', 'High', 'Low', 'Volume', 'Shiller PE Ratio', 'Close']]\n",
    "    return df\n",
    "\n",
    "def MergeByDate(df1, df2):\n",
    "    dfinal = df1.merge(df2, on=\"Date\", how = 'inner')\n",
    "    return dfinal\n",
    "\n",
    "\n",
    "#Looks like the derivatives of each are correlated\n",
    "#Even though maybe the magnitudes are not\n",
    "def GraphPEToClose(SandPData, PEData, logy = True):\n",
    "    if logy == False:\n",
    "        #PEData = ScalePERatio(PEData)\n",
    "        title = \"Graph of S&P and Schiller PE\"\n",
    "    else:\n",
    "         title = \"Graph of S&P and Schiller PE\"\n",
    "       \n",
    "    dfinal = MergeByDate(SandPData, PEData)\n",
    "    dfinal[:].plot(x='Date', y=['Close', 'Shiller PE Ratio'], figsize=(10,5), logy = logy, title = title, grid=True)\n",
    "\n",
    "def PEGraph():\n",
    "    SP = BuildSandPDataSet()\n",
    "    PE = BuildShillerPeDataSet()\n",
    "    GraphPEToClose(SP, PE)\n",
    "    \n",
    "def BuildInputSequence(dataset, window, prediction):\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0, len(dataset) - window + 1 - prediction):\n",
    "        feature = []\n",
    "        label = []\n",
    "        for j in range(0, window):\n",
    "            row = []\n",
    "            row.append(np.log(dataset['Open'][i + j]))\n",
    "            row.append(np.log(dataset['High'][i + j]))\n",
    "            row.append(np.log(dataset['Low'][i + j]))\n",
    "            row.append(np.log(dataset['Volume'][i + j]))\n",
    "            row.append(np.log(dataset['Shiller PE Ratio'][i + j]))\n",
    "            row.append(np.log(dataset['Close'][i + j]))\n",
    "            feature.append(row)\n",
    "\n",
    "        for j in range(0, prediction):\n",
    "            label.append(np.log(dataset['Close'])[i + window + j])\n",
    "\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return [features, labels]\n",
    "\n",
    "def TrainTestDataset(window = 1, prediction = 1):\n",
    "    df = BuildDataset()\n",
    "    a = BuildInputSequence(df, window, prediction)\n",
    "   \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(a[0], a[1], test_size = 0.2)\n",
    "\n",
    "    #X_train = a[0][:round(len(a[0])/2)]\n",
    "    #Y_train = a[0][(len(a[0]) - round(len(a[0])/2)) + 1:]\n",
    "\n",
    "    #X_test = a[1][:round(len(a[1])/2)]\n",
    "    #Y_test = a[1][(len(a[1]) - round(len(a[1])/2)) + 1:]\n",
    "    \n",
    "    return [X_train, Y_train, X_test, Y_test]\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_size, layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_size)\n",
    "        out = self.fc(out)\n",
    "        return out#, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.layers, batch_size, self.hidden_size).to(device)\n",
    "        return hidden\n",
    "    \n",
    "def Train(Model, X_train, Y_train, epochs, batchSize, learningRate):\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(Model.parameters(), lr=learningRate)\n",
    "    \n",
    "    dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "    dataLoader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batchSize, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, label) in enumerate(dataLoader):\n",
    "            data = data.to(device)\n",
    "            label = label.type(torch.float32)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = Model(data)\n",
    "            #output = output.squeeze(1)\n",
    "            output = output.float()\n",
    "            label = label.float()\n",
    "            #print(str(data), \"\\n\")\n",
    "            #print(str(output), \"\\n\")\n",
    "            #print(str(label), \"\\n\")\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #if(loss.item() < 0.01):\n",
    "                #print(\"Done Training..\")\n",
    "                #return\n",
    "            \n",
    "        print(\"Epoch: \" + str(epoch) + \" Loss: \" + str(loss.item()))\n",
    "    \n",
    "#rnn = RNN(6, 32, 1)\n",
    "D = TrainTestDataset(1)\n",
    "X_train, Y_train, X_test, Y_test = D[0], D[1], D[2], D[3]\n",
    "\n",
    "\n",
    "X_train = torch.Tensor(X_train)\n",
    "Y_train = torch.Tensor(Y_train)\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "\n",
    "Model = RNN(6, 1, 32, 1)\n",
    "Model = Model.to(device)\n",
    "\n",
    "Train(Model, X_train, Y_train, 100, 10, 0.01)\n",
    "\n",
    "#Getting Input size[30]\n",
    "#Expecting Output size [10, 1]\n",
    "\n",
    "#Getting Input size[12]\n",
    "#Expecting Output size [4, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de9e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
